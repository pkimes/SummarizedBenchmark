<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Estimate performance metrics in SummarizedBenchmark object — estimateMetricsForAssay • SummarizedBenchmark</title>

<link rel="shortcut icon" type="image/x-icon" href="../favicon.ico">

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.1/clipboard.min.js" integrity="sha256-hIvIxeqhGZF+VVeM55k0mJvWpQ6gTkWk3Emc+NmowYA=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Estimate performance metrics in SummarizedBenchmark object — estimateMetricsForAssay" />

<meta property="og:description" content="These functions estimate the performance metrics, either passed as arguments or
added previously with the addPerformanceMetric function. The function
will estimate the performance metric for each method." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SummarizedBenchmark</a>
        <span class="label label-info" data-toggle="tooltip" data-placement="bottom" title="Bioc Devel">1.99.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/SummarizedBenchmark-Introduction.html">Quick Start</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">General</li>
    <li>
      <a href="../articles/SummarizedBenchmark-Introduction.html">Introduction</a>
    </li>
    <li>
      <a href="../articles/SummarizedBenchmark-ClassDetails.html">Class Details</a>
    </li>
    <li>
      <a href="../articles/SummarizedBenchmark-FullCaseStudy.html">Full Case Study</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Features</li>
    <li>
      <a href="../articles/Feature-ErrorHandling.html">Error Handling</a>
    </li>
    <li>
      <a href="../articles/Feature-Iterative.html">Iterative Benchmarking</a>
    </li>
    <li>
      <a href="../articles/Feature-Parallel.html">Parallelization</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">More Case Studies</li>
    <li>
      <a href="../articles/CaseStudy-SingleCellSimulation.html">scRNA-seq Simulation</a>
    </li>
    <li>
      <a href="../articles/CaseStudy-RNAseqQuantification.html">RNA-seq Quantification</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/areyesq89/SummarizedBenchmark">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Estimate performance metrics in SummarizedBenchmark object</h1>
    <small class="dont-index">Source: <a href='https://github.com/areyesq89/SummarizedBenchmark/blob/master/R/PerformanceMetrics.R'><code>R/PerformanceMetrics.R</code></a></small>
    <div class="hidden name"><code>estimateMetrics.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>These functions estimate the performance metrics, either passed as arguments or
added previously with the <code><a href='addPerformanceMetric.html'>addPerformanceMetric</a></code> function. The function
will estimate the performance metric for each method.</p>
    
    </div>

    <pre class="usage"><span class='fu'>estimateMetricsForAssay</span>(<span class='no'>object</span>, <span class='no'>assay</span>, <span class='kw'>evalMetric</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>addColData</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>evalFunction</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>tidy</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)

<span class='fu'>estimatePerformanceMetrics</span>(<span class='no'>object</span>, <span class='kw'>addColData</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>tidy</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>rerun</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='no'>...</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>object</th>
      <td><p>A <code><a href='SummarizedBenchmark-class.html'>SummarizedBenchmark</a></code> object.</p></td>
    </tr>
    <tr>
      <th>assay</th>
      <td><p>A string with an assay name. Indicates the assay that should be
given as input to this performance metric.</p></td>
    </tr>
    <tr>
      <th>evalMetric</th>
      <td><p>A string with the name of the evaluation metric.</p></td>
    </tr>
    <tr>
      <th>addColData</th>
      <td><p>Logical (default: FALSE). If TRUE, the results are added to the
<code>colData</code> slot of the <code>SummarizedExperiment</code> object and
the object is returned. If FALSE, only a <code>DataFrame</code> with the results
is returned.</p></td>
    </tr>
    <tr>
      <th>evalFunction</th>
      <td><p>A function that calculates a performance metric. It should
contain at least two arguments, query and truth, where query is the output vector
of a method and truth is the vector of ground true values. If additional parameters
are specified, they must contain default values. If this parameter is passed,
the metrics in the object are ignored and only this evaluation metric
is estimated.</p></td>
    </tr>
    <tr>
      <th>tidy</th>
      <td><p>Logical (default: FALSE). If TRUE, a long formated <code>data.frame</code>
is returned.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Additional parameters passed to the performance functions.</p></td>
    </tr>
    <tr>
      <th>rerun</th>
      <td><p>Logical (default: TRUE). By default, all performance metrics are recalculated
everytime that <code>estimatePerformanceMetrics</code> is called. If FALSE, performance metrics
will only be calculated for newly added methods or modified methods.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>Either a <code><a href='SummarizedBenchmark.html'>SummarizedBenchmark</a></code> object, a <code>DataFrame</code> or
a <code>data.frame</code>.</p>
    
    <h2 class="hasAnchor" id="functions"><a class="anchor" href="#functions"></a>Functions</h2>

    <ul>
<li><p><code>estimateMetricsForAssay</code>: Estimate performance metrics for a given assay</p></li>
<li><p><code>estimatePerformanceMetrics</code>: Estimate performance metrics for all assays</p></li>
</ul>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='availableMetrics.html'>availableMetrics</a></code>, <code><a href='performanceMetrics.html'>performanceMetrics</a></code></p></div>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
<span class='fu'>data</span>( <span class='no'>sb</span> )
<span class='no'>sb</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='addPerformanceMetric.html'>addPerformanceMetric</a></span>(
   <span class='kw'>object</span><span class='kw'>=</span><span class='no'>sb</span>,
   <span class='kw'>assay</span><span class='kw'>=</span><span class='st'>"qvalue"</span>,
   <span class='kw'>evalMetric</span><span class='kw'>=</span><span class='st'>"TPR"</span>,
   <span class='kw'>evalFunction</span> <span class='kw'>=</span> <span class='kw'>function</span>( <span class='no'>query</span>, <span class='no'>truth</span>, <span class='no'>alpha</span><span class='kw'>=</span><span class='fl'>0.1</span> ){
       <span class='no'>goodHits</span> <span class='kw'>&lt;-</span> <span class='fu'>sum</span>( (<span class='no'>query</span> <span class='kw'>&lt;</span> <span class='no'>alpha</span>) <span class='kw'>&amp;</span> <span class='no'>truth</span> <span class='kw'>==</span> <span class='fl'>1</span> )
       <span class='no'>goodHits</span> / <span class='fu'>sum</span>(<span class='no'>truth</span> <span class='kw'>==</span> <span class='fl'>1</span>)
   }
)

<span class='no'>qvalueMetrics</span> <span class='kw'>&lt;-</span> <span class='fu'>estimateMetricsForAssay</span>( <span class='no'>sb</span>, <span class='kw'>assay</span><span class='kw'>=</span><span class='st'>"qvalue"</span> )
<span class='no'>allMetrics</span> <span class='kw'>&lt;-</span> <span class='fu'>estimatePerformanceMetrics</span>( <span class='no'>sb</span> )
<span class='no'>allMetricsTidy</span> <span class='kw'>&lt;-</span> <span class='fu'>estimatePerformanceMetrics</span>( <span class='no'>sb</span>, <span class='kw'>tidy</span><span class='kw'>=</span><span class='fl'>TRUE</span> )</div><div class='output co'>#&gt; <span class='warning'>Warning: `lang()` is soft-deprecated as of rlang 0.2.0.</span>
#&gt; <span class='warning'>Please use `call2()` instead</span>
#&gt; <span class='warning'>[90mThis warning is displayed once per session.[39m</span></div><div class='output co'>#&gt; <span class='warning'>Warning: `new_overscope()` is soft-deprecated as of rlang 0.2.0.</span>
#&gt; <span class='warning'>Please use `new_data_mask()` instead</span>
#&gt; <span class='warning'>[90mThis warning is displayed once per session.[39m</span></div><div class='output co'>#&gt; <span class='warning'>Warning: `overscope_eval_next()` is soft-deprecated as of rlang 0.2.0.</span>
#&gt; <span class='warning'>Please use `eval_tidy()` with a data mask instead</span>
#&gt; <span class='warning'>[90mThis warning is displayed once per session.[39m</span></div><div class='input'>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#functions">Functions</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Alejandro Reyes

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by <a href='http://alejandroreyes.org'>Alejandro Reyes</a>, <a href='https://www.pkimes.com'>Patrick Kimes</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

